Multi-Modal Content Analysis System with Bias and Safety Detection using Crew ai

Developed an advanced content analysis system integrating text and image processing using Crew AI, Groq's LLaMA LLM, and OpenAI's vision capabilities. This multi-agent system performs comprehensive analysis of mixed media content, including text evaluation, image analysis, bias detection, safety checking, and diversity assessment. Key features include:

- Text analysis using Groq's LLaMA LLM for efficient and accurate natural language processing
- Image interpretation leveraging OpenAI's advanced vision model
- Implements a multi-agent approach with specialized roles for thorough, multi-dimensional analysis
- Detects potential biases in both textual and visual content
- Identifies safety concerns and inappropriate content across different media types
- Assesses demographic diversity in textual descriptions and images
- Capable of updating datasets with bias and safety flags for further analysis and reporting


Tools used: Python, Crew AI, Groq API (LLaMA LLM), OpenAI API, LangChain, image processing libraries
<img width="1349" alt="Screen Shot 2024-07-24 at 11 24 15 pm" src="https://github.com/user-attachments/assets/4ec17c89-2124-4ae0-bb58-7c03a4e97f66">

<img width="586" alt="Screen Shot 2024-07-24 at 11 25 33 pm" src="https://github.com/user-attachments/assets/0aa354a0-80f0-4d94-acf7-28a29fd714a4">
<img width="666" alt="Screen Shot 2024-07-24 at 11 25 53 pm" src="https://github.com/user-attachments/assets/deda4094-14fc-449a-8006-8ff84929ee1d">
